{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: 文本分类\n",
    "\n",
    "- 本次作业的目标是实现一个文本分类的完整流程，包含数据预处理和二分类器。\n",
    "- 输入为电子邮件的文本，需要将其分类为 1(spam，垃圾邮件)或 0(ham，非垃圾邮件)，具体形式如下\n",
    "- 数据集(训练集)\n",
    "```python\n",
    "    └── train\n",
    "        ├── ham\n",
    "        │   ├── 0001.1999-12-10.farmer.ham.txt\n",
    "        │   ├── 0001.1999-12-10.kaminski.ham.txt\n",
    "        ......\n",
    "        │   ├── 5851.2001-05-22.kaminski.ham.txt\n",
    "        │   └── 5856.2001-05-22.kaminski.ham.txt\n",
    "        └── spam\n",
    "            ├── 0002.2001-05-25.SA_and_HP.spam.txt\n",
    "            ├── 0004.2004-08-01.BG.spam.txt\n",
    "            ......\n",
    "            ├── 5854.2005-07-22.SA_and_HP.spam.txt\n",
    "            └── 5857.2005-07-22.SA_and_HP.spam.txt\n",
    "    2 directories, 12406 files\n",
    "```\n",
    "\n",
    "----\n",
    "## 具体而言，你的任务是：\n",
    "\n",
    "### 1、完成对文本数据的预处理\n",
    "- 划分训练集和验证集\n",
    "- 用词向量等各种各样的形式对文本进行表征，方法包括但不限于'TF-IDF'\n",
    "\n",
    "### 2、选择一个课堂上学过的分类器，编写代码实现该分类器，可以调库\n",
    "\n",
    "### 3、在训练集上训练你的分类器\n",
    "- 模型输入为文本数据集所在的目录，输出应当为在你自己划分的验证集上的分类“准确率”与“召回率”与“F1-Score”\n",
    "\n",
    "### 4、提供可供 TA 一键测试的代码\n",
    "----\n",
    "\n",
    "## 评分规则：\n",
    "\n",
    "### 1、独立完成100 x 50%\n",
    "- 指你的代码可以一键运行不出bug\n",
    "\n",
    "### 2、测试集上的F1-Score x 100 x 50%\n",
    "- 如果测试集上的F1-Score 低于 0.6， 则视为0\n",
    "\n",
    "### 3、互相抄袭（指代码极其相似）的现象一经发现并核实，无论谁抄谁，双方本次作业成绩为0\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一些可用组件 & 示例\n",
    "- TA 提供了一些脚本函数可供使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# 将 list 写入到文件中\n",
    "def write_csv(data, file_name):\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(file_name, encoding='utf_8_sig')\n",
    "    \n",
    "# 从文件中读入数据\n",
    "def read_in_csv(file_name):\n",
    "    df = pd.read_csv(file_name)\n",
    "    return df\n",
    "\n",
    "# 获取某个路径下所有文件的路径，返回列表\n",
    "def file_name(file_dir):\n",
    "    L = []\n",
    "    path = []\n",
    "    for root, dirs, files in os.walk(file_dir):\n",
    "        for file in files:\n",
    "            xx = os.path.splitext(file)\n",
    "            if xx[1] == '.txt':\n",
    "                L.append(xx[0] + xx[1])\n",
    "                path.append(root)\n",
    "    return L, path\n",
    "\n",
    "# 评估指标\n",
    "def evaluation(true_label, pred_label):\n",
    "    precision = precision_score(true_label, pred_label)\n",
    "    recall = recall_score(true_label, pred_label)\n",
    "    F1_Score = f1_score(true_label, pred_label)\n",
    "    return precision, recall, F1_Score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 随便打开一个邮件看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: christmas tree farm pictures\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L, path = file_name('./train')\n",
    "with open(path[0] + '/' + L[0], \"r\", encoding='ISO-8859-1') as f:  \n",
    "    str = f.read()   \n",
    "    print(str)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 接下来，实现你的文本分类模型吧！\n",
    "- 数据预处理\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入为训练数据的路径\n",
    "train_data_path = './train'\n",
    "L, path = file_name(train_data_path)\n",
    "data=[]\n",
    "for i in range(len(L)):\n",
    "    with open(path[i] + '/' + L[i], \"r\", encoding='ISO-8859-1') as f:  \n",
    "        s = f.read()\n",
    "    data.append(s)\n",
    "label=(np.array(path)==train_data_path+'\\\\ham').astype('int')\n",
    "\n",
    "# 你需要将其划分为训练集和验证集\n",
    "Xtrain,Xtest,Ytrain,Ytest=train_test_split(data,label,test_size=0.2)\n",
    "\n",
    "# 选择一种你喜欢的形式将邮件文本表征成向量\n",
    "vectorizer=CountVectorizer()\n",
    "Xtrain=vectorizer.fit_transform(Xtrain)\n",
    "vectorizer2=CountVectorizer(vocabulary=vectorizer.vocabulary_)\n",
    "Xtest=vectorizer2.fit_transform(Xtest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 实现并训练分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.961\n",
      "Recall = 0.992\n",
      "F1_Score = 0.976\n"
     ]
    }
   ],
   "source": [
    "precision = 0.00000\n",
    "recall = 0.00000\n",
    "F1_Score = 0.00000\n",
    "\n",
    "#↓↓↓↓↓↓↓↓你的训练代码放在这↓↓↓↓↓↓↓↓#\n",
    "rfc=RandomForestClassifier(random_state=0)\n",
    "rfc=rfc.fit(Xtrain,Ytrain)\n",
    "precision, recall, F1_Score=evaluation(Ytest, rfc.predict(Xtest))\n",
    "#↑↑↑↑↑↑↑↑你的训练代码放在这↑↑↑↑↑↑↑↑#\n",
    "\n",
    "print('Precision = %.3f'% precision)\n",
    "print('Recall = %.3f'% recall)\n",
    "print('F1_Score = %.3f'% F1_Score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 实现测试代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#你可以自行将./train目录下的文件划分一部分作为测试集，并运行下一个cell中的代码查看分类器效果。上交作业后，TA 会将'test_data_path'变量的值修改为'test_data_path='./test'，./test不公开，文件组织形式与./train相同'\n",
    "test_data_path = './test'\n",
    "#你需要保证你的代码在./train上可以正常运行不出bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 1.000\n",
      "Recall = 1.000\n",
      "F1_Score = 1.000\n"
     ]
    }
   ],
   "source": [
    "precision = 0.00000\n",
    "recall = 0.00000\n",
    "F1_Score = 0.00000\n",
    "\n",
    "#↓↓↓↓↓↓↓↓测试代码放在这↓↓↓↓↓↓↓↓#\n",
    "L, path = file_name(test_data_path)\n",
    "data=[]\n",
    "for i in range(len(L)):\n",
    "    with open(path[i] + '/' + L[i], \"r\", encoding='ISO-8859-1') as f:  \n",
    "        s = f.read()\n",
    "    data.append(s)\n",
    "\n",
    "label=(np.array(path)==test_data_path+'\\\\ham').astype('int')\n",
    "Xtest=data\n",
    "# 不要忘记对测试数据进行向量化\n",
    "vectorizer3=CountVectorizer(vocabulary=vectorizer.vocabulary_)\n",
    "Xtest=vectorizer3.fit_transform(Xtest)\n",
    "precision, recall, F1_Score=evaluation(label, rfc.predict(Xtest))\n",
    "#↑↑↑↑↑↑↑↑测试代码放在这↑↑↑↑↑↑↑↑#\n",
    "print('Precision = %.3f'% precision)\n",
    "print('Recall = %.3f'% recall)\n",
    "print('F1_Score = %.3f'% F1_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "19376542de715cbac5d171dda8af81ecf79e038461c0d2df32f2ab6da82c2493"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
